from dotenv import load_dotenv
import openai
import os
from fpdf import FPDF
from analise_anomalias import detectar_anomalias_video_unico  # <- NOVO

# === CONFIGURAÃ‡Ã•ES ===

load_dotenv()

openai.api_key = os.getenv("OPENROUTER_API_KEY")
openai.api_base = "https://openrouter.ai/api/v1"

if not openai.api_key:
    raise ValueError("âŒ A chave de API do OpenRouter nÃ£o foi definida. Define a variÃ¡vel de ambiente OPENROUTER_API_KEY.")

TXT_PATH = "output/vehicle_counts.txt"


# === FUNÃ‡Ã•ES ===

def parse_vehicle_stats(txt_path):
    stats = {}
    total = 0

    with open(txt_path, 'r', encoding='utf-8') as file:
        lines = file.readlines()

    current_class = None
    for line in lines:
        line = line.strip()

        if line.startswith("Classe:"):
            current_class = line.split(":")[1].strip()
            stats[current_class] = {}
        elif "- Contagem:" in line:
            stats[current_class]["count"] = int(line.split(":")[1].strip())
        elif "- Percentagem:" in line:
            stats[current_class]["percentage"] = float(line.split(":")[1].strip().replace("%", ""))
        elif "- ConfianÃ§a mÃ©dia:" in line:
            stats[current_class]["avg_conf"] = float(line.split(":")[1].strip())
        elif line.startswith("TOTAL DETETADO:"):
            total = int(line.split(":")[1].strip())

    return stats, total


def formatar_anomalias(anomalias):
    if not anomalias:
        return "Nenhuma anomalia foi detetada com base nas estatÃ­sticas deste vÃ­deo."

    texto = "As seguintes anomalias foram detetadas na anÃ¡lise local do vÃ­deo:\n"
    for a in anomalias:
        texto += f"- {a}\n"
    return texto


def generate_prompt(stats, total, anomalias_texto=""):
    prompt = (
        "Gere um relatÃ³rio tÃ©cnico e estruturado com base nas seguintes estatÃ­sticas de contagem de veÃ­culos.\n"
        "O relatÃ³rio deve seguir este formato e estrutura obrigatÃ³rios:\n\n"

        "=== EstatÃ­sticas Gerais ===\n"
        "Inclua o total de veÃ­culos detetados.\n\n"

        "=== AnÃ¡lise por Classe ===\n"
        "Para cada classe, apresente de forma clara:\n"
        "- Nome da classe\n"
        "- NÃºmero de veÃ­culos detetados\n"
        "- Percentagem em relaÃ§Ã£o ao total\n"
        "- ConfianÃ§a mÃ©dia (com duas casas decimais)\n\n"

        "=== Anomalias Detetadas ===\n"
        "Liste cada anomalia detetada com bullet points (â€¢).\n"
        "Se nÃ£o existirem anomalias, escreva: 'Nenhuma anomalia foi detetada.'\n\n"

        "Evite cortar informaÃ§Ã£o. Use linhas completas. Use linguagem clara e objetiva.\n"
        "Evite frases demasiado longas e nÃ£o omita dados relevantes.\n\n"

        "=== Dados para AnÃ¡lise ===\n"
        f"Total de veÃ­culos detetados: {total}\n"
    )

    for cls, data in stats.items():
        prompt += (
            f"\nClasse: {cls}\n"
            f"- Contagem: {data['count']}\n"
            f"- Percentagem: {data['percentage']}%\n"
            f"- ConfianÃ§a mÃ©dia: {data['avg_conf']:.2f}\n"
        )

    if anomalias_texto:
        prompt += "\n\n=== AnÃ¡lise de Anomalias ===\n"
        prompt += anomalias_texto

    prompt += "\n\nGere o relatÃ³rio seguindo rigorosamente o formato acima."
    return prompt


def gerar_relatorio_llm(prompt, modelo="mistralai/mistral-7b-instruct"):
    try:
        response = openai.ChatCompletion.create(
            model=modelo,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.6,
            max_tokens=1500
        )
        return response["choices"][0]["message"]["content"]
    except openai.error.OpenAIError as e:
        return f"âŒ Erro ao gerar relatÃ³rio com o LLM: {str(e)}"


def limpar_caracteres(texto):
    """Remove ou substitui caracteres incompatÃ­veis com a codificaÃ§Ã£o 'latin-1' usada pelo FPDF."""
    substituicoes = {
        "â—": "[!]",
        "âš ï¸": "[AtenÃ§Ã£o]",
        "â†’": "->",
        "â€“": "-",
        "â€”": "-",
        "â€™": "'",
        "â€œ": '"',
        "â€": '"',
        "â€¢": "-",
        "âœ”": "[ok]",
        "âœ–": "[x]",
        "ðŸ›ˆ": "[info]",
        "âž¡": "->"
    }
    for char, substituto in substituicoes.items():
        texto = texto.replace(char, substituto)
    return texto


def gerar_pdf(relatorio_texto, caminho_pdf):
    pdf = FPDF()
    pdf.add_page()
    pdf.set_auto_page_break(auto=True, margin=15)
    pdf.set_font("Arial", size=12)

    # Limpar caracteres antes de gerar PDF
    relatorio_texto = limpar_caracteres(relatorio_texto)

    for linha in relatorio_texto.split("\n"):
        pdf.multi_cell(0, 10, txt=linha)

    pdf.output(caminho_pdf)


# === EXECUÃ‡ÃƒO PRINCIPAL ===

def main():
    stats, total = parse_vehicle_stats(TXT_PATH)

    # Nova anÃ¡lise de anomalias (sem histÃ³rico)
    anomalias = detectar_anomalias_video_unico(stats, total)
    texto_anomalias = formatar_anomalias(anomalias)

    # GeraÃ§Ã£o do prompt
    prompt = generate_prompt(stats, total, texto_anomalias)

    print("\nðŸ”¹ PROMPT ENVIADO PARA O LLM:\n")
    print(prompt)

    print("\nðŸ”¸ RELATÃ“RIO GERADO PELO LLM:\n")
    relatorio = gerar_relatorio_llm(prompt)
    print(relatorio)

    # Guardar como .txt
    relatorio_txt_path = "output/relatorio_gerado.txt"
    with open(relatorio_txt_path, "w", encoding='utf-8') as f:
        f.write(relatorio)
    print(f"\nâœ… RelatÃ³rio de texto guardado em: {relatorio_txt_path}")

    # Guardar como PDF
    relatorio_pdf_path = "output/relatorio_gerado.pdf"
    gerar_pdf(relatorio, relatorio_pdf_path)
    print(f"\nâœ… RelatÃ³rio PDF guardado em: {relatorio_pdf_path}")


if __name__ == "__main__":
    main()
